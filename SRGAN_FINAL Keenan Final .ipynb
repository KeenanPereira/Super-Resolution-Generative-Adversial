{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Check GPU & Install Dependencies =====\n",
        "#@title **1.1 Check GPU**\n",
        "!nvidia-smi\n",
        "\n",
        "#@title **1.2 Install Python Packages**\n",
        "!pip install torch torchvision pillow scikit-image tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ok9bjKP8Nq",
        "outputId": "ca65dcbe-442c-4fe1-a929-5317be97f312"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May  9 04:48:22 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2. Download & Prepare DIV2K HR =====\n",
        "\n",
        "# Download & Flatten HR images**\n",
        "import os, glob, shutil\n",
        "\n",
        "# Cleanup old data\n",
        "!rm -rf data/DIV2K_train_HR data/DIV2K_train_HR.zip temp_DIV2K\n",
        "os.makedirs('data/DIV2K_train_HR', exist_ok=True)\n",
        "\n",
        "# Download DIV2K HR zip\n",
        "!wget -q https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip -O data/DIV2K_train_HR.zip\n",
        "\n",
        "# Unzip into temp and flatten all images into data/DIV2K_train_HR\n",
        "!unzip -q data/DIV2K_train_HR.zip -d temp_DIV2K\n",
        "for pattern in ('*.png','*.jpg','*.jpeg'):\n",
        "    for fp in glob.glob(f\"temp_DIV2K/{pattern}\") + glob.glob(f\"temp_DIV2K/*/{pattern}\"):\n",
        "        shutil.move(fp, 'data/DIV2K_train_HR/')\n",
        "# Cleanup\n",
        "!rm -rf data/DIV2K_train_HR.zip temp_DIV2K\n",
        "\n",
        "# Verify\n",
        "hr_files = glob.glob(\"data/DIV2K_train_HR/*\")\n",
        "print(f\"Found {len(hr_files)} HR images in data/DIV2K_train_HR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMEPzHEQP8QH",
        "outputId": "142a7e6d-99cc-43a0-9eaa-876ecf246051"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 HR images in data/DIV2K_train_HR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 3. Define Models =====\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import vgg19\n"
      ],
      "metadata": {
        "id": "7YZR5l1yP8Sa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **3.2 ResidualBlock & Generator**\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, n_feats=64):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(n_feats, n_feats, 3, 1, 1),\n",
        "            nn.BatchNorm2d(n_feats),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(n_feats, n_feats, 3, 1, 1),\n",
        "            nn.BatchNorm2d(n_feats),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, n_res_blocks=16, n_feats=64, scale=4):\n",
        "        super().__init__()\n",
        "        self.conv_in = nn.Conv2d(3, n_feats, 9, 1, 4)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(n_feats) for _ in range(n_res_blocks)])\n",
        "        self.conv_mid = nn.Sequential(nn.Conv2d(n_feats, n_feats, 3, 1, 1), nn.BatchNorm2d(n_feats))\n",
        "        upsample = []\n",
        "        for _ in range(int(scale/2)):\n",
        "            upsample += [\n",
        "                nn.Conv2d(n_feats, n_feats*4, 3, 1, 1),\n",
        "                nn.PixelShuffle(2),\n",
        "                nn.PReLU()\n",
        "            ]\n",
        "        self.upsample = nn.Sequential(*upsample)\n",
        "        self.conv_out = nn.Conv2d(n_feats, 3, 9, 1, 4)\n",
        "    def forward(self, x):\n",
        "        x1 = self.prelu(self.conv_in(x))\n",
        "        res = self.res_blocks(x1)\n",
        "        res = self.conv_mid(res)\n",
        "        x2 = x1 + res\n",
        "        out = self.upsample(x2)\n",
        "        return self.conv_out(out)"
      ],
      "metadata": {
        "id": "W1V3XUZQQuZU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **3.3 Discriminator**\n",
        "def conv_block(in_c, out_c, s):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, 3, s, 1),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "    )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.LeakyReLU(0.2, inplace=True),\n",
        "            conv_block(64, 64, 2), conv_block(64, 128, 1),\n",
        "            conv_block(128, 128, 2), conv_block(128, 256, 1),\n",
        "            conv_block(256, 256, 2), conv_block(256, 512, 1),\n",
        "            conv_block(512, 512, 2), nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(), nn.Linear(512, 1024), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 1), nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "9sXtWPFzQuTm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **3.4 VGG Feature Extractor**\n",
        "class VGGFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        vgg = vgg19(pretrained=True).features\n",
        "        self.slice = nn.Sequential(*list(vgg)[:36])\n",
        "        for p in self.slice.parameters():\n",
        "            p.requires_grad = False\n",
        "    def forward(self, x):\n",
        "        return self.slice(x)"
      ],
      "metadata": {
        "id": "PWlUHU7sQuMp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4. Patch-based Dataset & DataLoader =====\n",
        "\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "class SRPatchDataset(Dataset):\n",
        "    def __init__(self, hr_dir, patch_size=96, scale=4):\n",
        "        super().__init__()\n",
        "        self.hr_paths = sorted(glob.glob(f\"{hr_dir}/*\"))\n",
        "        self.patch_size = patch_size\n",
        "        self.scale = scale\n",
        "        self.to_tensor = ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr = Image.open(self.hr_paths[idx]).convert(\"RGB\")\n",
        "        w, h = hr.size\n",
        "        # ensure random patch fits\n",
        "        ps = self.patch_size\n",
        "        if w < ps or h < ps:\n",
        "            hr = hr.resize((max(ps,w), max(ps,h)), Image.BICUBIC)\n",
        "            w, h = hr.size\n",
        "        left = random.randint(0, w - ps)\n",
        "        top  = random.randint(0, h - ps)\n",
        "        hr_patch = hr.crop((left, top, left + ps, top + ps))\n",
        "        lr_patch = hr_patch.resize((ps // self.scale, ps // self.scale), Image.BICUBIC)\n",
        "        return self.to_tensor(lr_patch), self.to_tensor(hr_patch)\n",
        "\n",
        "# instantiate dataset & loader\n",
        "dataset = SRPatchDataset('data/DIV2K_train_HR', patch_size=96, scale=4)\n",
        "loader  = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "print(f\"Dataset size: {len(dataset)} patches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFGzx6i1P8Ut",
        "outputId": "dac8bfe8-5e60-451b-a780-fefa7d9aa59e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 800 patches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5. Training Setup =====\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "VGG = VGGFeatureExtractor().to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "mse = nn.MSELoss()\n",
        "bce = nn.BCELoss()\n",
        "optG = optim.Adam(G.parameters(), lr=1e-4)\n",
        "optD = optim.Adam(D.parameters(), lr=1e-4)\n",
        "t_real = lambda n: torch.ones((n,1), device=device)\n",
        "t_fake = lambda n: torch.zeros((n,1), device=device)"
      ],
      "metadata": {
        "id": "aWWIt78FP8Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c405a6-2f2d-4d73-fecd-8418c64f4859"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6. Phase 1: MSE Pre-training =====\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "epochs_pre = 15\n",
        "for epoch in range(epochs_pre):\n",
        "    loop = tqdm(loader, desc=f\"Pretrain {epoch+1}/{epochs_pre}\")\n",
        "    for lr_img, hr_img in loop:\n",
        "        lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
        "        optG.zero_grad()\n",
        "        sr = G(lr_img)\n",
        "        loss = mse(sr, hr_img)\n",
        "        loss.backward()\n",
        "        optG.step()\n",
        "        loop.set_postfix(mse=loss.item())\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "torch.save(G.state_dict(), 'checkpoints/srgan_pretrained.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaCE3P88P8aI",
        "outputId": "c2db1ada-8173-40b1-b9f1-9aaf09a18544"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pretrain 1/15: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, mse=0.0132]\n",
            "Pretrain 2/15: 100%|██████████| 50/50 [00:57<00:00,  1.14s/it, mse=0.0217]\n",
            "Pretrain 3/15: 100%|██████████| 50/50 [00:55<00:00,  1.11s/it, mse=0.0131]\n",
            "Pretrain 4/15: 100%|██████████| 50/50 [00:56<00:00,  1.12s/it, mse=0.00802]\n",
            "Pretrain 5/15: 100%|██████████| 50/50 [00:56<00:00,  1.13s/it, mse=0.00643]\n",
            "Pretrain 6/15: 100%|██████████| 50/50 [00:55<00:00,  1.11s/it, mse=0.00764]\n",
            "Pretrain 7/15: 100%|██████████| 50/50 [00:55<00:00,  1.11s/it, mse=0.00751]\n",
            "Pretrain 8/15: 100%|██████████| 50/50 [00:55<00:00,  1.10s/it, mse=0.0095]\n",
            "Pretrain 9/15: 100%|██████████| 50/50 [00:56<00:00,  1.14s/it, mse=0.00999]\n",
            "Pretrain 10/15: 100%|██████████| 50/50 [00:54<00:00,  1.10s/it, mse=0.00448]\n",
            "Pretrain 11/15: 100%|██████████| 50/50 [00:54<00:00,  1.10s/it, mse=0.00625]\n",
            "Pretrain 12/15: 100%|██████████| 50/50 [00:55<00:00,  1.12s/it, mse=0.00473]\n",
            "Pretrain 13/15: 100%|██████████| 50/50 [00:55<00:00,  1.11s/it, mse=0.0107]\n",
            "Pretrain 14/15: 100%|██████████| 50/50 [00:55<00:00,  1.12s/it, mse=0.0143]\n",
            "Pretrain 15/15: 100%|██████████| 50/50 [00:54<00:00,  1.10s/it, mse=0.0055]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7. Phase 2: Adversarial Training =====\n",
        "\n",
        "epochs_gan = 25\n",
        "for epoch in range(epochs_gan):\n",
        "    loop = tqdm(loader, desc=f\"GAN {epoch+1}/{epochs_gan}\")\n",
        "    for lr_img, hr_img in loop:\n",
        "        lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
        "        # Discriminator step\n",
        "        optD.zero_grad()\n",
        "        sr_det = G(lr_img).detach()\n",
        "        lossD = 0.5 * (bce(D(hr_img), t_real(lr_img.size(0))) +\n",
        "                       bce(D(sr_det), t_fake(lr_img.size(0))))\n",
        "        lossD.backward()\n",
        "        optD.step()\n",
        "        # Generator step\n",
        "        optG.zero_grad()\n",
        "        sr = G(lr_img)\n",
        "        content_loss = mse(VGG(sr), VGG(hr_img))\n",
        "        adv_loss     = bce(D(sr), t_real(lr_img.size(0)))\n",
        "        lossG = content_loss + 1e-3 * adv_loss\n",
        "        lossG.backward()\n",
        "        optG.step()\n",
        "        loop.set_postfix(D=lossD.item(), G=lossG.item())\n",
        "    torch.save(G.state_dict(), f'checkpoints/srgan_GAN_epoch{epoch+1}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut-UWKZ9P8l4",
        "outputId": "ea64514e-bc46-4636-c29a-5319309f29de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GAN 1/25: 100%|██████████| 50/50 [00:58<00:00,  1.17s/it, D=0.1, G=0.124]\n",
            "GAN 2/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.0334, G=0.173]\n",
            "GAN 3/25: 100%|██████████| 50/50 [00:58<00:00,  1.17s/it, D=0.00456, G=0.163]\n",
            "GAN 4/25: 100%|██████████| 50/50 [00:57<00:00,  1.15s/it, D=0.00796, G=0.127]\n",
            "GAN 5/25: 100%|██████████| 50/50 [00:59<00:00,  1.19s/it, D=0.0471, G=0.111]\n",
            "GAN 6/25: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, D=0.00455, G=0.171]\n",
            "GAN 7/25: 100%|██████████| 50/50 [00:57<00:00,  1.15s/it, D=0.00479, G=0.144]\n",
            "GAN 8/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.00148, G=0.142]\n",
            "GAN 9/25: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, D=0.00123, G=0.206]\n",
            "GAN 10/25: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, D=0.0155, G=0.132]\n",
            "GAN 11/25: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, D=0.00526, G=0.125]\n",
            "GAN 12/25: 100%|██████████| 50/50 [00:57<00:00,  1.15s/it, D=0.00662, G=0.0959]\n",
            "GAN 13/25: 100%|██████████| 50/50 [00:58<00:00,  1.17s/it, D=0.00109, G=0.174]\n",
            "GAN 14/25: 100%|██████████| 50/50 [00:56<00:00,  1.13s/it, D=0.000592, G=0.189]\n",
            "GAN 15/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.000492, G=0.206]\n",
            "GAN 16/25: 100%|██████████| 50/50 [00:57<00:00,  1.14s/it, D=0.000533, G=0.152]\n",
            "GAN 17/25: 100%|██████████| 50/50 [00:59<00:00,  1.18s/it, D=0.000431, G=0.21]\n",
            "GAN 18/25: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it, D=0.00539, G=0.122]\n",
            "GAN 19/25: 100%|██████████| 50/50 [00:56<00:00,  1.14s/it, D=0.00165, G=0.0917]\n",
            "GAN 20/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.125, G=0.136]\n",
            "GAN 21/25: 100%|██████████| 50/50 [00:58<00:00,  1.17s/it, D=0.00297, G=0.112]\n",
            "GAN 22/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.00251, G=0.132]\n",
            "GAN 23/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.00174, G=0.118]\n",
            "GAN 24/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.00267, G=0.119]\n",
            "GAN 25/25: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it, D=0.00127, G=0.103]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 8. Evaluation & Metrics =====\n",
        "# 8.1 Identify & Load Checkpoint\n",
        "import os, re\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "ckpts = os.listdir('checkpoints')\n",
        "print(\"Available checkpoints:\", ckpts)\n",
        "\n",
        "gan_ckpts = [f for f in ckpts if 'srgan_GAN_epoch' in f]\n",
        "if gan_ckpts:\n",
        "    # pick highest‐numbered epoch\n",
        "    epochs = {int(re.search(r'epoch(\\d+)', f).group(1)): f for f in gan_ckpts}\n",
        "    best = epochs[max(epochs)]\n",
        "    ckpt_path = os.path.join('checkpoints', best)\n",
        "else:\n",
        "    ckpt_path = os.path.join('checkpoints', 'srgan_pretrained.pth')\n",
        "\n",
        "print(\"Loading checkpoint:\", ckpt_path)\n",
        "G.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "G.eval()\n",
        "to_pil = ToPILImage()\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# 8.2 Super-Resolve Sample Patches\n",
        "for i in range(10):\n",
        "    lr, _ = dataset[i]\n",
        "    with torch.no_grad():\n",
        "        sr = G(lr.unsqueeze(0).to(device))\n",
        "    to_pil(sr.squeeze(0).cpu()).save(f'results/sample_{i}.png')\n",
        "print(\"Saved samples to results/\")\n",
        "\n",
        "# 8.3 Compute PSNR & SSIM (with a fallback for small images)\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "import skimage.color as sc\n",
        "\n",
        "psnr_vals, ssim_vals = [], []\n",
        "for i in range(10):\n",
        "    # load SR and HR\n",
        "    sr = np.array(Image.open(f'results/sample_{i}.png')) / 255.0\n",
        "    _, hr_tensor = dataset[i]\n",
        "    hr = hr_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # PSNR\n",
        "    psnr_vals.append(peak_signal_noise_ratio(hr, sr, data_range=1.0))\n",
        "\n",
        "    # SSIM—prefer color, but fallback to grayscale if window too large\n",
        "    try:\n",
        "        ssim_vals.append(structural_similarity(hr, sr,\n",
        "                                               channel_axis=2,\n",
        "                                               data_range=1.0))\n",
        "    except ValueError:\n",
        "        hr_gray = sc.rgb2gray(hr)\n",
        "        sr_gray = sc.rgb2gray(sr)\n",
        "        ssim_vals.append(structural_similarity(hr_gray,\n",
        "                                               sr_gray,\n",
        "                                               data_range=1.0))\n",
        "\n",
        "print(f\"Avg PSNR: {np.mean(psnr_vals):.2f}, Avg SSIM: {np.mean(ssim_vals):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttDIY3lWQbo7",
        "outputId": "866f5596-02ee-412f-839d-6a59757d1d25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available checkpoints: ['srgan_GAN_epoch20.pth', 'srgan_GAN_epoch7.pth', 'srgan_GAN_epoch23.pth', 'srgan_GAN_epoch17.pth', 'srgan_GAN_epoch22.pth', 'srgan_GAN_epoch19.pth', 'srgan_GAN_epoch6.pth', 'srgan_GAN_epoch11.pth', 'srgan_GAN_epoch21.pth', 'srgan_GAN_epoch10.pth', 'srgan_GAN_epoch9.pth', 'srgan_GAN_epoch16.pth', 'srgan_GAN_epoch18.pth', 'srgan_GAN_epoch15.pth', 'srgan_GAN_epoch12.pth', 'srgan_pretrained.pth', 'srgan_GAN_epoch24.pth', 'srgan_GAN_epoch25.pth', 'srgan_GAN_epoch8.pth', 'srgan_GAN_epoch13.pth', 'srgan_GAN_epoch4.pth', 'srgan_GAN_epoch1.pth', 'srgan_GAN_epoch5.pth', 'srgan_GAN_epoch14.pth', 'srgan_GAN_epoch3.pth', 'srgan_GAN_epoch2.pth']\n",
            "Loading checkpoint: checkpoints/srgan_GAN_epoch25.pth\n",
            "Saved samples to results/\n",
            "Avg PSNR: 7.11, Avg SSIM: 0.0348\n"
          ]
        }
      ]
    }
  ]
}