# SRGAN & Enhanced SRGAN

This repository implements two Generative Adversarial Network (GAN)-based pipelines for image super-resolution using PyTorch:

- *Baseline SRGAN*: Original SRGAN architecture with 16 Residual Blocks.
- *Enhanced SRGAN*: An improved generator using Residual-in-Residual Dense Blocks (RRDB).

Both pipelines are trained on the DIV2K dataset to map low-resolution (LR) bicubic-downsampled inputs back to high-resolution (HR) images.

## Contents

1. [Installation](#installation)
2. [Dataset Download & Preprocessing](#dataset-download--preprocessing)
3. [Custom Dataset & DataLoader](#custom-dataset--dataloader)
4. [Model Architectures](#model-architectures)
   - Baseline SRGAN
   - Enhanced Generator with RRDB
5. [Training](#training)
   - Baseline SRGAN (train_srgan)
   - Enhanced SRGAN (train_enhanced)
6. [Evaluation](#evaluation)
7. [Example Usage](#example-usage)
8. [File Structure](#file-structure)
9. [References](#references)

---

## Installation

bash
# Clone the repository
git clone <repo_url>
cd <repo_folder>

# Install dependencies
pip install torch torchvision pillow scikit-image tqdm


## Dataset Download & Preprocessing

1. *Download DIV2K HR Images*:
   python
   if not os.path.isdir('DIV2K_train_HR'):
       wget -q https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip
       unzip -q DIV2K_train_HR.zip
       rm DIV2K_train_HR.zip
   
2. *Generate LR Images* (scale factor = 4):
   python
   from PIL import Image
   import os

   def create_lr(hr_dir='DIV2K_train_HR', lr_dir='DIV2K_train_LR', scale=4):
       os.makedirs(lr_dir, exist_ok=True)
       for fn in os.listdir(hr_dir):
           if not fn.lower().endswith(('png','jpg')):
               continue
           hr = Image.open(f'{hr_dir}/{fn}').convert('RGB')
           w, h = hr.size
           # Bicubic downsample & upsample
           lr = hr.resize((w//scale, h//scale), Image.BICUBIC)
           lr = lr.resize((w, h), Image.BICUBIC)
           lr.save(f'{lr_dir}/{fn}')

   create_lr()
   

## Custom Dataset & DataLoader

python
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Compose, ToTensor, Normalize
from PIL import Image

class DIV2KDataset(Dataset):
    def __init__(self, hr_dir, lr_dir, transform=None):
        self.hr_dir, self.lr_dir = hr_dir, lr_dir
        self.fns = [f for f in os.listdir(hr_dir) if f.lower().endswith(('png','jpg'))]
        self.transform = transform or Compose([
            ToTensor(),
            Normalize((0.5,)*3, (0.5,)*3)
        ])

    def __len__(self):
        return len(self.fns)

    def __getitem__(self, i):
        hr = Image.open(f'{self.hr_dir}/{self.fns[i]}').convert('RGB')
        lr = Image.open(f'{self.lr_dir}/{self.fns[i]}').convert('RGB')
        return self.transform(lr), self.transform(hr)


Wrap in a DataLoader:
python
dataset = DIV2KDataset('DIV2K_train_HR', 'DIV2K_train_LR')
dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)


## Model Architectures

### Baseline SRGAN
- *Generator*: Initial 9Ã—9 conv + PReLU, 16 Residual Blocks, skip connection, upsampling stages, final 9Ã—9 conv.
- *Discriminator*: Series of Convâ†’BNâ†’LeakyReLU layers, global pooling, dense layers, single output logit.

### Enhanced Generator with RRDB
- *DenseResidualBlock (DRB)*: 5 conv layers with dense connectivity, 1Ã—1 conv fusion, scaled residual.
- *RRDB*: 3 DRBs with overall skip connection.
- *EnhancedGenerator*: Initial conv + PReLU, RRDB trunk (default 23 blocks), trunk conv + skip, two upsample stages, final conv.

For detailed architectural diagrams and rationale, see the project report. îˆ€citeðŸš¢turn0file0ðŸš¶

## Training

### Baseline SRGAN (train_srgan)
python
train_srgan(
    hr_dir='DIV2K_train_HR',
    lr_dir='DIV2K_train_LR',
    epochs=200,
    bs=16,
    lr=1e-4,
    save_every=10
)

#### Losses
- *Content Loss*: MSE(gen, hr)
- *Adversarial Loss*: BCE
to fool discriminator
- *Pixel Loss*: Scaled MSE

### Enhanced SRGAN (train_enhanced)
python
train_enhanced(
    hr_dir='DIV2K_train_HR',
    lr_dir='DIV2K_train_LR',
    sr_ckpt='gen_200.pth',
    epochs=100,
    bs=16,
    lr=1e-4,
    save_every=10
)

Warm-start from a pretrained SRGAN checkpoint.

## Evaluation
python
evaluate(
    ckpt='enh_gen_100.pth',
    hr_dir='DIV2K_train_HR',
    lr_dir='DIV2K_train_LR',
    enhanced=True
)

Outputs average *PSNR* and *SSIM* metrics over the test set.

## Example Usage
bash
# Train baseline for 30 epochs
torchscript> python main.py --mode train_srgan --epochs 30

# Train enhanced with warm-start
torchscript> python main.py --mode train_enhanced --sr_ckpt gen_200.pth --epochs 30

# Evaluate enhanced at epoch 30
torchscript> python main.py --mode evaluate --ckpt enh_gen_100.pth --enhanced


## File Structure

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ DIV2K_train_HR/       # High-resolution images
â”‚   â””â”€â”€ DIV2K_train_LR/       # Generated low-resolution images
â”œâ”€â”€ generator.py              # SRGAN Generator implementation
â”œâ”€â”€ discriminator.py          # Discriminator implementation
â”œâ”€â”€ model.py                  # Training and evaluation entrypoint
â”œâ”€â”€ dataset.py                # DIV2KDataset definition
â”œâ”€â”€ loss.py                   # Custom loss functions
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ report.pdf                # Detailed project report îˆ€citeðŸš¢turn0file0ðŸš¶


## References
- Ledig et al., "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network", CVPR 2017.
- Wang et al., "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks", ECCV 2018.
- Project report: Super-Resolution Generative Adversarial Network îˆ€citeðŸš¢turn0file0ðŸš¶

---

Happy super-resolving!
